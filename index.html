---
layout: default
---

<main class="content">
    <section>
        <h2>&nbsp;
            <span class="section-label">"To play a wrong note is insignificant; to play without passion is inexcusable."</span>
        </h2>
    </section>

    <section>
        <h2>Hyperalignment</h2>
        <p>
            Aligning intelligent, agentic systems to human values is misguided, and we ought instead focus on incorporating the rich computational structure of metaphysical objects, based on insights from moral epistemology.
        </p>
        <div class="two-column">
            <a href="/ought-squared">
                <div class="list-item">
                    <h4>Ought Squared</h4>
                    <p>One ought to contemplate what one ought to do.</p>
                </div>
            </a>
            <a href="https://compphil.github.io/truth/">
                <div class="list-item">
                    <h4>Elements of Computational Philosophy</h4>
                    <p>Rendering philosophy computable and verifiable.</p>
                </div>
            </a>
        </div>
    </section>

    <section>
        <h2>Strategic Deceleration</h2>
        <p>
            However, incremental progress towards hyperalignment would be of limited use if civilization disempowerment occurs in the meantime. This line of work is focused on buying time under a <a href="https://docs.google.com/document/d/e/2PACX-1vTjsSHYSx7qHJBooCmVuz9c9bNeJiqS7o6Jt1Vb-l2wU3D4Ka7IM-X4p_CB8Ncil2ayLOkqiD4Fdlf7/pub">first-principles threat model</a>.
        </p>
        <div class="two-column">
            <a href="https://noemaresearch.com/blog/join-autohack-2024-tournament">
                <div class="list-item">
                    <h4>Capability Demonstrations</h4>
                    <p>Legibly demonstrating dual-use capabilities.</p>
                </div>
            </a>
            <a href="/geopolitics-of-computation">
                <div class="list-item">
                    <h4>Coordination Technology</h4>
                    <p>Enabling a geopolitics of computation.</p>
                </div>
            </a>
        </div>
    </section>

    <section>
        <h2>Strategic Acceleration</h2>
        <p>
            Besides, hyperalignment work prior to automated research will likely amount to little, given future millenia of intellectual progress in a glimpse. This line of work is focused on capturing value from capability advances through "agent readiness" efforts.
        </p>
        <!-- <div class="two-column">
            <a>
                <div class="list-item">
                    <h4>Agent Readiness</h4>
                    <p>Productively assimilating non-human contributions.</p>
                </div>
            </a>
            <a>
                <div class="list-item">
                    <h4>Workflow Optimization</h4>
                    <p>Cognitive ergonomics, systematic biohacking, behavioral engineering.</p>
                </div>
            </a>
        </div> -->
    </section>

    <section>
        <h2>Acknowledgements</h2>
        <p>
            I'm grateful for having been supported in my work, either financially or through compute, either recently or less so, by <a href="https://www.openphilanthropy.org/grants/straumli-llm-cyberoffense-benchmark/">Open Philantropy</a>, <a href="https://funds.effectivealtruism.org/grants?search=paul+bricman&sort=round">Long-Term Future Fund</a>, <a href="https://sites.research.google/trc/about/">Google Research</a>, <a href="https://www.alignmentforum.org/posts/5uiQkyKdejX3aEHLM/how-to-diversify-conceptual-alignment-the-model-behind#Some_Concrete_Details">Conjecture</a>, <a href="https://stability.ai/">Stability AI</a>, <a href="https://web.archive.org/web/20230712223102/https://aisafety.camp/#Projects">AI Safety Camp</a>, and <a href="https://github.com/sponsors/paulbricman">Andreas Stuhlm√ºller</a>.
        </p>
    </section>
</main>