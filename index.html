---
layout: default
---

<main class="content">
  <div class="two-column-layout">
    <div class="column">
      <div class="content-block">
        <h2>
          <span class="section-label">
            I'm interested in ensuring that the machines that will shape the
            future will do what ought to be done. My two contributions here are
            listed below. I also enjoy writing about related topics.
          </span>
        </h2>
      </div>
    </div>
  </div>

  <div class="two-column-layout">
    <div class="column">
      <div class="content-block">
        <h2>Virtual Diplomacy</h2>
        <p>
          I believe that coordinated action is the most promising approach to
          developing AI safely, and that the most promising approach to
          coordinated action involves verification. This line of work is focused
          on developing infrastructure for reliably verifying AI usage, and
          applying it to enable coordination.
          <a
            href="https://noemaresearch.com/blog/virtual-diplomacy"
            class="read-more"
            >Read more.</a
          >
        </p>
      </div>

      <div class="content-block">
        <h2>Computational Philosophy</h2>
        <p>
          I believe that we ought to develop AI systems that reason about what
          they ought to do, instead of what people want them to do. This line of
          work is focused on elaborating a moral epistemology of bounded agents,
          and applying it to sculpt AI behavior.
          <a href="/ought-squared" class="read-more">Read more.</a>
        </p>
      </div>
    </div>

    <div class="column">
      <div class="content-block">
        <h2>Writing</h2>
        <div class="writings-list">
          {% for post in site.posts limit:15 %}
          <a href="{{ post.url }}" class="writing-item">{{ post.title }}</a>
          {% endfor %}

          <a href="/archive" class="writing-item">...</a>
        </div>
      </div>

      <div class="content-block">
        <h2>Acknowledgements</h2>
        <p>
          I'm grateful for having been supported in my work, either financially
          or through compute, either recently or less so, by
          <a
            href="https://www.openphilanthropy.org/grants/straumli-llm-cyberoffense-benchmark/"
            >Open Philanthropy</a
          >,
          <a
            href="https://funds.effectivealtruism.org/grants?search=paul+bricman&sort=round"
            >Long-Term Future Fund</a
          >,
          <a href="https://sites.research.google/trc/about/">Google Research</a
          >,
          <a
            href="https://www.alignmentforum.org/posts/5uiQkyKdejX3aEHLM/how-to-diversify-conceptual-alignment-the-model-behind#Some_Concrete_Details"
            >Conjecture</a
          >, <a href="https://stability.ai/">Stability AI</a>,
          <a
            href="https://web.archive.org/web/20230712223102/https://aisafety.camp/#Projects"
            >AI Safety Camp</a
          >, and
          <a href="https://github.com/sponsors/paulbricman"
            >Andreas Stuhlm√ºller</a
          >.
        </p>
      </div>
    </div>
  </div>
</main>
