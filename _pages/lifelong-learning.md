---
layout: page
---

## lifelong learning

I plan on using my bachelor-to-master gap year (2022-2023) as a pilot project in self-guided learning. It will involve a year-long curriculum focused on upskilling in ML engineering and AI safety, complete with modules and tracks. For friends and family, this page should reply to the question of what the heck I'm doing with my life this year. For future employers, it should lend support to the idea that I enjoy learning new things. For everybody else, it might motivate you to consider running similar projects yourself, because it's unexpectedly fun, especially the planning!

- background

Soon after starting to entertain this idea, I realized that curriculum design is not as straight-forward as it might seem. This felt especially true after spending all my life in formal education, where important parts of the curriculum are predefined -- presumably to help you focus on what mattersâ„¢. Just like using managed cloud services lead me to have no idea how container orchestration works, outsourcing curriculum design to a university lead me to be overwhelmed when tackling the task myself. Outside the comfort of external scheduling, sandbox assignments, and delegated evaluation, you take full responsibility for your training. It's full of learning with and from others, yet it's you who decides why and what you're learning.

Besides wanting to upskill in ML engineering and AI safety, another motivation was that I'll likely consider some form of homeschooling a few eons into the future. From what I've heard, you can never be too prepared for it. This ties nicely with the fact that many tools I'm experimenting with are designed to help users learn effectively. What better incentive for building those than deschooling society?

As a final motivation, I'd like to make a name for myself based on what I can actually create, rather than based on a big-brand affiliation. I feel that relying on a fancy degree or title might make me more comfortable and complacent than I'd like to be. Going forward, I feel I'd be more content knowing that I can live up to my expectations without invoking a recognized name to fill in the gaps.

Why not just try getting involved in an AI safety research group looking for ML engineers, learn things that way? First, there's a chicken-egg problem. I currently lack familiarity with AI safety paradigms and decent ML engineering skills, especially when it comes to handling large models or datasets. This makes it hard to get into those settings, which makes this approach less feasible. A hyperfocused curriculum seems to me a more reliable and directed way of acquainting myself with those topics, before getting involved more heavily with those orgs later on. Second, I feel there's stronger specialization as you move to more established research groups. At this stage, I want to get a broad sense of the whole range of tasks involved in research engineering in this space. Third, I really want to hone those self-guided learning skills and take full responsability for my learning process. Therefore, only part of the curriculum will consist in practical work in the industry and academia.

- curriculum

The latest version of my curriculum consists of a few tracks: engineering, alignment, research, and hobby. Each track consists of a sequence of specific modules. Tracks provide an intermediate level in organization, halfway between individual modules and the complete curriculum, which turned out to simplify scheduling. Tracks don't necessarily have to switch modules at the same time, as periods and semesters often to in formal education -- it's difficult to perfectly predict how long those things take. However, in order not to get overwhelmed and chaotic, each track follows one module at a time (except for the hobby one). I have no idea how long each track will take or whether I'll finish it before the gap year ends, yet I'm content with whatever it is I'll manage. Currently, each module below lists a brief learning objective, but I'll create individual pages for them as the year progresses.

I selected modules based roughly on a mix of the following heuristics. Most modules have a combination of them as motivation, but I listed some representative examples:

1. What foundational concepts would I find important to nail? (e.g. automatic differentiation in computational graphs)
2. What skills would I find useful to apply in my work? (e.g. putting together explorable explanations in data-driven documents)
3. What artifacts would I find useful to have? (e.g. a self-hosted Google Scholar replica in distributed analytics? Yes, please!)
4. If I'd be recruiting for an ML engineer or research engineer role, what skills would I find most valuable in prospective candidates? (e.g. multi-node multi-GPU training in distributed training)
5. If I were to take on a meaningful research project as a one-man-research-group (horrible idea, but useful as heuristic), what skills would I be missing? (e.g. awareness of the research landscape in trends in language modeling)

| track       | module                           | learning objective                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| ----------- | -------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| engineering | cloud computing                  | Set up a personal cloud based on a [Kubernetes](https://kubernetes.io/) cluster. Deploy both third-party (e.g. [Nextcloud](https://nextcloud.com/)) and original containers (e.g. [conceptarium](/thoughtware/conceptarium)) on it.                                                                                                                                                                                                                   |
|             | distributed inference            | Set up a loose replica of the [Hugging Face](https://huggingface.co/) [Inference API](https://api-inference.huggingface.co/docs/python/html/index.html) on the previously-deployed cluster. Implement GPU acceleration, model pinning, caching, batching, and logging.                                                                                                                                                                                |
|             | distributed analytics            | Set up a loose replica of [Google Scholar](https://scholar.google.com/) based on a subset of papers crawled from [Sci-Hub](https://sci-hub.ru/). Should make use of the previously-deployed inference engine for semantic search, summarization, and question answering. Should also make use of tools like [Spark](https://spark.apache.org/).                                                                                                       |
|             | distributed training             | Use the previouly-collected data to fine-tune [GPT-J](https://6b.eleuther.ai/) or a [BERT](https://huggingface.co/roberta-base) variant. Should make use of ephemeral [vast.ai](https://vast.ai/) nodes attached to the previously-deployed cluster. Contemplate the legality of a language model trained on pirated content before publishing it anyway.                                                                                             |
|             | computational graphs             | Implement a [minimal version of PyTorch from scratch](https://minitorch.github.io/). Should cover tensors, automatic differentiation, and full networks. A part two might consist in implementing a [relatively straight-forward paper](https://arxiv.org/pdf/2103.03206.pdf) using [JAX](https://jax.readthedocs.io/en/latest/jax-101/index.html).                                                                                                   |
|             | data-driven documents            | Implement three interactive articles using [D3.js](https://d3js.org/). Should help convey an intuitive explanation of abstract concepts in ML or AI safety.                                                                                                                                                                                                                                                                                           |
| alignment   | trends in language modeling      | Read through the resources on language modeling and auxiliary topics listed in the [reading list](https://docs.google.com/document/d/1Z1mQ47FqzNBzNvalWgSnyGph7A4Q7MndOEqsqv_mto0/edit#heading=h.4khaz12c49ll) compiled by [Andreas](https://stuhlmueller.org/) from [Ought](https://ought.org/). Should result in at least three explainer or commentary blog posts, and a non-trivial amount of cold emailing to relevant researchers for feedback. |
|             | introduction to AI safety        | Read through the resources linked in the alignment curriculum put together as part of the [AGI Safety Fundamentals](https://www.eacambridge.org/technical-alignment-curriculum) course offered by [EA Cambridge](https://www.eacambridge.org/). Should result in at least three explainer or commentary blog posts, possibly cross-posted on the [alignment forum](https://www.alignmentforum.org/).                                                  |
|             | foundations of humane technology | Follow the [eponymous course](https://www.humanetech.com/course) offered by [Center for Humane Technology](https://www.humanetech.com/) (i.e. the people behind [The Social Dilemma](https://www.humanetech.com/the-social-dilemma)). Not AI-specific, but appears to be a good primer on building user-centered products and value-based design in general. Should result in at least three explainer or commentary blog posts.                      |
|             | deep reinforcement learning      | Watch the [RL Lecture Series](https://deepmind.com/learning-resources/reinforcement-learning-series-2021) offered by DeepMind and UCL, especially the second half. Should result in at least three explainer or commentary blog posts, and a non-trivial amount of cold emailing to relevant researchers for feedback.                                                                                                                                |
| research    | belief systems                   | As per [my existing research agenda](/reflections/twenty-one), I want to prototype tools for debugging and editing belief systems. Should result in open source prototypes accompanied by informal write-ups and possibly more in-depth papers.                                                                                                                                                                                                       |
|             | embodied knowledge work          | Similar context and expected outputs to the above. I want to experiment with tools which help us bring more of our embodied knowledge into our knowledge work.                                                                                                                                                                                                                                                                                        |
|             | TBD                              | I should be looking into at least another couple research themes by the end of the gap year (e.g. tutoring systems, human-AI creativity, etc.). This is where I'm open to collaboration with folks from industry and academia. **If you'd like to work together on derisking HCI ideas or prototyping novel user-facing mechanics, let's get in touch!**                                                                                              |
| hobby       | representational drawing         | Follow this [superb course](https://drawabox.com/) on the topic. Should result in ten pieces of concept art depicting futurist interfaces and, naturally, cute robots.                                                                                                                                                                                                                                                                                |
|             | modular synthesis                | Continues the artsy theme of the previous module, but switches to music. Should be based on digital Eurorack simulators like [VCV Rack 2](https://vcvrack.com/). Should result in ten ambient electronic soundscapes.                                                                                                                                                                                                                                 |
|             | chinese                          | Follow the [Refold](https://refold.la/) methodology for language acquisition and related Mandarin resources. Should result in an HSK 4 certificate.                                                                                                                                                                                                                                                                                                   |
|             | driving                          | What it says on the tin. Should result in not running anyone over, I guess.                                                                                                                                                                                                                                                                                                                                                                           |

- study with me

It's unlikely that I'll come across someone having similar plans during the same period, but feel free to reach out if you want to keep in touch while going through one of the above modules, mostly for fun and accountability. I'll probably also look for accountability partners on relevant subreddits or Discord servers.

- acknowledgements

Thanks to the people who spared a bit of their time to offer feedback on those plans, including [Alex Lawsen](https://twitter.com/lxrjl), [Andy Jones](https://andyljones.com/), [Luke Stebbing](https://ought.org/team), and pseudonymous folks on the [EleutherAI](https://www.eleuther.ai/), [ML Collective](https://mlcollective.org/), and [vast.ai](https://vast.ai/) servers. I'm also extremely grateful for the people supporting my work on [GitHub Sponsors](https://github.com/sponsors/paulbricman), especially [Andreas StuhlmÃ¼ller](https://stuhlmueller.org/). Finally, the constant support from my SO has been instrumental in getting this whole thing going.
